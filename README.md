# ğŸš€ E-Commerce Big Data Pipeline  
## Architecture Medallion â€“ 9.3 Go de donnÃ©es (â‰ˆ 25M Ã©vÃ©nements)


## ğŸ§  Contexte & Objectifs

Ce projet met en Å“uvre un **pipeline Big Data de bout en bout** destinÃ© Ã  traiter un dataset e-commerce massif de **9.3 Go** (â‰ˆ **25 millions dâ€™Ã©vÃ©nements utilisateurs**).

ğŸ¯ **Objectifs principaux :**
- Concevoir un pipeline ETL scalable et robuste
- Appliquer une **Architecture Medallion (Bronze / Silver / Gold)**
- Optimiser les performances Spark (I/O, shuffles, mÃ©moire)
- Produire des **donnÃ©es analytiques exploitables par le mÃ©tier**
- GÃ©nÃ©rer des **KPIs de rentabilitÃ© e-commerce**

Le projet sâ€™inscrit dans une logique **Data Engineering orientÃ©e production**.

---

## ğŸ—ï¸ Architecture Medallion

Lâ€™architecture est organisÃ©e en trois couches garantissant **qualitÃ©, traÃ§abilitÃ© et performance** :

### ğŸ¥‰ Bronze â€“ Raw Layer
- Ingestion des fichiers CSV bruts
- Lecture optimisÃ©e via **Column Pruning**
- Conservation des donnÃ©es sources sans transformation
- Objectif : **traÃ§abilitÃ© & audit**

### ğŸ¥ˆ Silver â€“ Refined Layer
- Nettoyage avancÃ© et normalisation
- Typage strict des colonnes (**Schema Enforcement**)
- Application de **8 tests de qualitÃ© des donnÃ©es**
- Stockage au format **Apache Parquet** partitionnÃ©
- Objectif : **fiabilitÃ© & cohÃ©rence**

### ğŸ¥‡ Gold â€“ Curated Layer
- Enrichissement mÃ©tier
- Jointures optimisÃ©es via **Broadcast Join**
- AgrÃ©gations analytiques (CA, marges, volumes)
- Alimentation dâ€™une base SQL analytique
- Objectif : **prise de dÃ©cision**

---

## âš¡ Optimisations & Performance

Le pipeline a Ã©tÃ© conÃ§u pour exploiter efficacement le calcul distribuÃ© Spark :

| Optimisation | Description | Impact |
|---|---|---|
| **Apache Parquet** | Format colonnaire compressÃ© | ğŸš€ Lecture **3.9x plus rapide** |
| **Partitionnement** | Par `event_type` | ğŸ“‰ RÃ©duction massive des I/O |
| **Broadcast Join** | Diffusion des petites tables | âŒ Suppression du shuffle |
| **Schema Enforcement** | Typage strict en Silver | âœ… 0 erreur critique |
| **Lazy Evaluation** | Exploitation du moteur Spark | âš™ï¸ ExÃ©cution optimisÃ©e |

---

## ğŸ“Š DonnÃ©es & Insights Business

Les donnÃ©es finales sont exposÃ©es via une base SQL analytique :

ğŸ“‚ **Base :** `ecommerce_db`

### KPIs produits :
- ğŸ† **Top marques par chiffre dâ€™affaires**
- ğŸ“ˆ **Analyse de marges par catÃ©gorie**
- ğŸ’° DÃ©tection de **marques Ã  forte rentabilitÃ© (~15%)**
- ğŸ§ª **Audit qualitÃ© du catalogue**
- ğŸ” Suivi du comportement utilisateur

Ces indicateurs permettent un **pilotage stratÃ©gique des ventes e-commerce**.

---

## ğŸ§° Stack Technique

- **Apache Spark 3.x**
- **Databricks**
- **Python (PySpark)**
- **Apache Parquet**
- **SQL Analytics**
- **Dataset REES46 (Kaggle)**

---

## ğŸ“ Structure du Projet

```bash
project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ bronze/                 # DonnÃ©es brutes (Raw Layer)
â”‚   â”‚   â”œâ”€â”€ main/               #Source 1
â”‚   â”‚   â””â”€â”€ enrich/             #Source 2
â”‚   â”‚
â”‚   â”œâ”€â”€ silver/                 # DonnÃ©es nettoyÃ©es et normalisÃ©es
â”‚   â”‚   â”œâ”€â”€ main_clean/         # Nettoyage des donnÃ©es principales
â”‚   â”‚   â”œâ”€â”€ enrich_clean/       # Nettoyage des donnÃ©es enrichies
â”‚   â”‚   â””â”€â”€ joined/             # Jointures validÃ©es
â”‚   â”‚
â”‚   â””â”€â”€ gold/                   # DonnÃ©es mÃ©tier prÃªtes Ã  lâ€™analyse
â”‚       â”œâ”€â”€ marts/              # Tables analytiques (Data Marts)
â”‚       â”œâ”€â”€ aggregates/         # KPIs et agrÃ©gations mÃ©tier
â”‚       â””â”€â”€ exports/            # Exports finaux (CSV / SQL)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/              # Scripts dâ€™ingestion (Bronze)
â”‚   â”œâ”€â”€ transforms/             # Transformations Spark (Silver & Gold)
â”‚   â”œâ”€â”€ quality/                # Tests et contrÃ´les qualitÃ©
â”‚   â””â”€â”€ utils/                  # Fonctions utilitaires communes
â”‚
â”œâ”€â”€ notebooks/                  # Notebooks Databricks (exploration & pipeline)
â”œâ”€â”€ configs/                    # Fichiers de configuration
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ data_quality/           # Rapports de qualitÃ© des donnÃ©es
â”‚   â””â”€â”€ benchmarks/             # Mesures de performance & optimisations
â”‚
â””â”€â”€ README.md                   # Documentation du projet

